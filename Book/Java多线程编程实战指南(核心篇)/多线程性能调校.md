# 多线程性能调校

#### 内部锁的优化

(1)锁消除
锁消除(LockElision)是JIT编译器对内部锁的具体实现所做的一种优化。 在动态编译同步块的时候, JIT编译器可以借助一种被称为逃逸分析(Escape Analysis)的技术来判断同步块所使用的锁对象是否只能够被一个线程访问而没有被发布到其他线程。 如果同步块所使用的锁对象通过这种分析被证实只能够被一个线程访问, 那么JIT编译器在编译这个同步块的时候并不生成synchronized所表示的锁的申请与释放对应的机器码, 而仅生成原临界区代码对应的机器码, 这就造成了被动态编译的字节码就像是不包含monitorenter(申请锁)和monitorexit(释放锁)这两个字节码指令一样, 即消除了锁的使用。 这种编译器优化就被称为锁消除(Lock Elision), 它使得特定情况下我们可以完全消除锁的开销。 
```java
	
	// 待编译的代码  有且只要一个线程会执行这段代码
	synchronized(monitor) {
		doSomethings();
	}

	// 优化后的代码
	doSomethings();
```
Java标准库中的有些类(比如StringBuffer)虽然是线程安全的, 但是在实际使用中我们往往不在多个线程间共享这些类的实例。 而这些类在实现线程安全的时候往往借助于内部锁。 因此, 这些类是锁消除优化的常见目标。 
```java

	public static String toJson(ProductInfo info) {

		/**
		 * JIT编译器在编译toJSON方法的时候会将其调用的StringBuffer.append/toString方法内联(Inline)到该方法之中, 
		 * 这相当于把StringBuffer.append/toString方法的方法体中的指令复制到toJSON方法体之中。 (既把其代码拷贝到方法里面)	
		 * 此时的sb是一个局部变量，并且该变量所引用的对象并没有被发布到其他线程, 
		 * 因此sbf引用的对象只能够被sb所在的方法(toJSON方法)的当前执行线程(一个线程)访问。 
		 * 所以, JIT编译器此时可以消除toJSON方法中从StringBuffer.append/toString方法的方法体复制的指令所使用的内部锁。 
		 */
		StringBuffer sb = new StringBuffer();
		sb.append("{\"productID\":\"").append(info.getProductId());
		sb.append(",\"inventory\":").append(productInfo.inventory);
		sb.append("\"}");
		return sb.toString();
	}
```
从上述例子可以看出, 锁消除优化还可能需要以JIT编译器的内联优化为前提。 而一个方法是否会被JIT编译器内联取决于该方法的热度以及该方法对应的字节码的尺寸(BytecodeSize)[4]。 因此, 锁消除优化能否被实施还取决于被调用的同步方法(或者带同步块的方法)是否能够被内联。 锁消除优化能否被实施还取决于被调用的同步方法(或者带同步块的方法)是否能够被内联。 

锁消除优化并不表示开发人员在编写代码的时候可以随意使用内部锁(在不需要加锁的情况下加锁), 因为锁消除是JIT编译器而不是javac所做的一种优化, 而一段代码只有在其被执行的频率足够大的情况下才有可能会被JIT编译器优化[5]。 也就是说在JIT编译器优化介入之前, 只要源代码中使用了内部锁, 那么这个锁的开销就会存在。 另外, JIT编译器所执行的内联优化、逃逸分析以及锁消除优化本身都是有其开销的。 


(2)锁粗化
锁粗化(Lock Coarsening/Lock Merging)是JIT编译器对内部锁的具体实现所做的一种优化, 对于相邻的几个同步块, 如果这些同步块使用的是同一个锁实例, 那么JIT编译器会将这些同步块合并为一个大同步块, 从而避免了一个线程反复申请、释放同一个锁所导致的开销。 然而, 锁粗化可能导致一个线程持续持有一个锁的时间变长, 从而使得同步在该锁之上的其他线程在申请锁时的等待时间变长。 
```java
	synchronized(monitor) {
		doSomethings1();
	}
	// 此处, 原本是可以被其他线程争夺，获取锁monitor的
	synchronized(monitor) {
		doSomethings2();
	}

	synchronized(monitor) {
		doSomethings3();
	}

	//优化后
	synchronized(monitor) {
		doSomethings1();
		doSomethings2();
		doSomethings3();
	}
```
相邻的两个同步块之间如果存在其他语句, 也不一定就会阻碍JIT编译器执行锁粗化优化, 这是因为JIT编译器可能在执行锁粗化优化前将这些语句挪到(即指令重排序)后一个同步块的临界区之中(当然, JIT编译器并不会将临界区内的代码挪到临界区之外)。 

在实际中，很小会出现上面例子的情况,下面的例子
```java

	public class Demo  {

		private final Random rnd = new Random();

		public void simulate(){
			int iq1 = randomIQ(); 
			int iq2 = randomIQ();
			int iq3 = randomIQ();
			act(iq1,iq2,iq3);
		}

		public void act(int... num) {

		}

		// 返回随机数
		public int randomIQ(){
			// rnd.nexGaussian() 是一个同步方法
			return (int)Math.round(rnd.nextGaussian() ＊ 15 + 100);
		}

	}
```
如上: simulate方法连续调用randomIQ方法来生成3个随机数, 在simulate方法被执行得足够频繁的情况下, JIT编译器可能对该方法执行一系优化：首先, JIT编译器可能将randomIQ方法内联(inline)到simulate方法中, 这相当于把randomIQ方法体中的指令复制到simulate方法之中。 这相当于把randomIQ方法体中的指令复制到simulate方法之中。 在此基础上, randomIQ方法中的rnd.nextGaussian()调用也可能被内联, 这相当于把Random.nextGaussian()方法体中的指令复制到simulate方法之中。 Random.nextGaussian()是一个同步方法, 由于Random实例rnd可能被多个线程共享(因为simulate方法可能被多个线程执行), 因此JIT编译器无法对Random.nextGaussian()方法本身执行锁消除优化, 这使得被内联到simulate方法中的Random.nextGaussian()方法体相当于一个由rnd引导的同步块。 

锁粗化默认是开启的。 如果要关闭这个特性, 我们可以在Java程序的启动命令行中添加虚拟机参数"-XX:-EliminateLocks"(开启则可以使用虚拟机参数"-XX:+EliminateLocks")。 

(3) 偏向锁
　　偏向锁(Biased Locking)是Java虚拟机对锁的实现所做的一种优化。 这种优化基于这样的观测结果(Observation)：大多数锁并没有被争用(Contented), 并且这些锁在其整个生命周期内至多只会被一个线程持有。 然而, Java虚拟机在实现monitorenter字节码(申请锁)和monitorexit字节码(释放锁)时需要借助一个原子操作(CAS操作), 这个操作代价相对来说比较昂贵。 因此, Java虚拟机会为每个对象维护一个偏好(Bias), 即一个对象对应的内部锁第1次被一个线程获得, 那么这个线程就会被记录为该对象的偏好线程(BiasedThread)。 这个线程后续无论是再次申请该锁还是释放该锁, 都无须借助原先(指未实施偏向锁优化前)昂贵的原子操作, 从而减少了锁的申请与释放的开销。 

　　然而, 一个锁没有被争用并不代表仅仅只有一个线程访问该锁, 当一个对象的偏好线程以外的其他线程申请该对象的内部锁时, Java虚拟机需要收回(Revoke)该对象对原偏好线程的"偏好"并重新设置该对象的偏好线程。 这个偏好收回和重新分配过程的代价也是比较昂贵的, 因此如果程序运行过程中存在比较多的锁争用的情况, 那么这种偏好收回和重新分配的代价便会被放大。 有鉴于此, 偏向锁优化只适合于存在相当大一部分锁并没有被争用的系统之中。

偏向锁优化默认是开启的。 要关闭偏向锁优化, 我们可以在Java程序的启动命令行中添加虚拟机参数"-XX:-UseBiasedLocking"(开启偏向锁优化可以使用虚拟机参数"-XX:+UseBiasedLocking")。 

(４) 适应性锁
适应性锁(AdaptiveLocking, 也被称为AdaptiveSpinning)是JIT编译器对内部锁实现所做的一种优化。 
　　存在锁争用的情况下, 一个线程申请一个锁的时候如果这个锁恰好被其他线程持有, 那么这个线程就需要等待该锁被其持有线程释放。 实现这种等待的一种保守方法：将这个线程暂停(线程的生命周期状态变为非Runnable状态)。 由于暂停线程会导致上下文切换, 因此对于一个具体锁实例来说, 这种实现策略比较适合于系统中绝大多数线程对该锁的持有时间较长的场景, 这样才能够抵消上下文切换的开销。 另外一种实现方法就是采用忙等(BusyWait)。就如一个空的循环` while(lockIsHeldByOtherThread) {}`

　　可见, 忙等是通过反复执行空操作(什么也不做)直到所需的条件成立为止而实现等待的。 这种策略的好处是不会导致上下文切换, 缺点是比较耗费处理器资源——如果所需的条件在相当长时间内未能成立, 那么忙等的循环就会一直被执行。 因此, 对于一个具体的锁实例来说, 忙等策略比较适合于绝大多数线程对该锁的持有时间较短的场景, 这样能够避免过多的处理器时间开销。

　　事实上, Java虚拟机也不是非要在上述两种实现策略之中择其一——它可以综合使用上述两种策略。 对于一个具体的锁实例, Java虚拟机会根据其运行过程中收集到的信息来判断这个锁是属于被线程持有时间"较长"的还是"较短"的。 对于被线程持有时间"较长"的锁, Java虚拟机会选用暂停等待策略; 而对于被线程持有时间"较短"的锁, Java虚拟机会选用忙等等待策略。 Java虚拟机也可能先采用忙等等待策略, 在忙等失败的情况下再采用暂停等待策略[7]。 Java虚拟机的这种优化就被称为适应性锁(AdaptiveLocking), 这种优化同样也需要JIT编译器介入。  

　　从适应性锁优化可以看出, 内部锁的使用并不一定会导致上下文切换

#### 优化对锁的使用