# 多线程编程的硬件基础

#### 1. 高速缓存
1. 在现代的计算器中, 主内存执行一次内存读、写操作所需的时间可能足够处理器执行上百条的指令。为了弥补处理器与主内存处理能力之间的鸿沟，硬件设计者在主内存和处理器之间引入了高速缓存（Cache）。

 ![Alt '高速缓存'](https://github.com/LCN29/Picture-Repository/blob/master/MyNote/Book/cache.png?raw=true)

>1. 如图, 每个处理器都有其高速缓存。引入高速缓存之后，处理器在执行内存读、写操作的时候并不直接与主内存打交道，而是通过高速缓存进行的。
>2. 在代码中变量名相当于内存地址，而变量值则相当于相应内存空间所存储的数据。 高速缓存相当于为程序所访问的每个变量保留了一份相应内存空间所存储数据（变量值）的副本。高速缓存相当于一个由硬件实现的容量极小的散列表（HashTable），其键（Key）是一个内存地址，其值（Value）是内存数据的副本或者准备写入内存的数据。
>3. 从内部结构来看，高速缓存相当于一个拉链散列表（ChainedHashTable），它包含若干桶（Bucket，硬件上称之为Set），每个桶又可以包含若干缓存条目(CacheEntry), 如图
 ![Alt '高速缓存内部结构'](https://github.com/LCN29/Picture-Repository/blob/master/MyNote/Book/cache-structure.png?raw=true)

2. 缓存条目可被进一步划分为Tag、DataBlock以及Flag这三个部分，其中，DataBlock也被称为缓存行（CacheLine），它是高速缓存与主内存之间的数据交换最小单元，用于存储从内存中读取的或者准备写往内存的数据。Tag则包含了与缓存行中数据相应的内存地址的部分信息（内存地址的高位部分比特）。Flag用于表示相应缓存行的状态信息。从代码的角度来看，一个缓存行可以存储若干变量的值，而多个变量的值则可能被存储在同一个缓存行之中。

3. 处理器在执行内存访问操作时会将相应的内存地址解码内存地址的解码结果包括tag、index以及以及offset这三部分数据。其中，index相当于桶编号，它可以用来定位内存地址对应的桶；一个桶可能包含多个缓存条目，tag相当于缓存条目的相对编号，其作用在于用来与同一个桶中的各个缓存条目中的Tag部分进行比较，以定位一个具体的缓存条目；一个缓存条目中的缓存行可以用来存储多个变量，offset是缓存行内的位置偏移，其作用在于确定一个变量在一个缓存行中的存储起始位置。根据这个内存地址的解码结果，如果高速缓存子系统能够找到相应的缓存行并且缓存行所在的缓存条目的Flag表示相应缓存条目是有效的，那么我们就称相应的内存操作产生了缓存命中(CacheHit)否则，我们就称相应的内存操作产生了缓存未命中（CacheMiss)。

4. 现代处理器一般具有多个层次的高速缓存，一级缓存通常包括两部分，其中一部分用于存储指令（L1i），另外一部分用于存储数据（L1d）。距离处理器越近的高速缓存，其存取速率越快，制造成本越高，因此其容量也越小。距离处理器越远（即距离主内存越近）的高速缓存，其存储速率会越慢，而存储容量则相应地增大。


#### 2. 缓存一致性协议
MESI（Modified-Exclusive-Shared-Invalid）协议是一种广为使用的缓存一致性协议，它使得针对同一地址的读内存操作是并发的，而针对同一地址的写内存操作是独占的，即针对同一内存地址进行的写操作在任意一个时刻只能够由一个处理器执行。在MESI协议中，一个处理器往内存中写数据时必须持有该数据的所有权。为了保障数据的一致性，MESI将缓存条目的状态划分为Modified、Exclusive、Shared和Invalid这4种，并在此基础上定义了一组消息（Message）用于协调各个处理器的读、写内存操作。

(1)MESI协议中一个缓存条目的Flag值有以下4种可能。

|状态值                    | 表示的含义 |
|:-:                       | 			-: |
| Invalid （无效的，记为I） | 相应缓存行中不包含任何内存地址对应的有效副本数据。该状态是缓存条目的初始状态|
| Shared（共享的，记为S）   | 相应缓存行包含相应内存地址所对应的副本数据。并且，其他处理器上的高速缓存中也可能包含相同内存地址对应的副本数据,处于该状态的缓存条目，其缓存行中包含的数据与主内存中包含的数据一致|
| Exclusive（独占的，记为E）| 相应缓存行包含相应内存地址所对应的副本数据。并且，该缓存行以独占的方式保留了相应内存地址的副本数据，即其他所有处理器上的高速缓存当前都不保留该数据的有效副本。处于该状态的缓存条目，其缓存行中包含的数据与主内存中包含的数据一致|
| Modified（更改过的，记为M）| 相应缓存行包含对相应内存地址所做的更新结果数据。由于MESI协议中的任意一个时刻只能够有一个处理器对同一内存地址对应的数据进行更新，因此在多个处理器上的高速缓存中Tag值相同的缓存条目中，任意一个时刻只能够有一个缓存条目处于该状态。处于该状态的缓存条目，其缓存行中包含的数据与主内存中包含的数据不一致|

(2)MESI协议定义了一组消息（Message）用于协调各个处理器的读、写内存操作。

|消息名| 消息类型 | 描述 |
| :-: | :-: | -:   |
| Read | 请求 | 通知其他处理器、主内存当前处理器准备读取某个数据。该消息包含待读取数据的内存地址 |
| ReadResponse | 响应 | 该消息包含被请求读取的数据。该消息可能是主内存提供的，也可能是嗅探Read消息的其他高速缓存提供的 |
| Invalidate | 请求 | 通知其他处理器将其高速缓存中指定内存地址对应的缓存条目状态置为I，即通知这些处理器删除指定内存地址的副本数据 |
| Invalidate Acknowledge | 响应 | 接收到Invalidate消息的处理器必须回复该消息，以表示删除了其高速缓存上的相应副本数据 |
| Read Invalidate | 请求  | 该消息是由Read消息和Invalidate消息组合而成的复合消息。其作用在于通知其他处理器当前处理器准备更新（Read-Modify-Write，读后写更新）一个数据，并请求其他处理器删除其高速缓存中相应的副本数据。接收到该消息的处理器必须回复ReadResponse消息和InvalidateAcknowledge消息|
| Writeback | 请求 | 该消息包含需要写入主内存的数据及其对应的内存地址|

处理器在执行内存读、写操作时在必要的情况下会往总线（Bus）中发送特定的请求消息，同时每个处理器还嗅探（Snoop，也称拦截）总线中由其他处理器发出的请求消息并在一定条件下往总线中回复相应的响应消息。

>1. 例子1： 处理器读取值
假设: 内存地址A,对应的数据为 S, 有处理器P1, 处理器P2, 处理器P1读取内存 地址A的数据值
>>1. P1根据内存地址A到自身的高速缓存中查找缓存目录, 并读取改缓存条目的Tag和Flag。找到的缓存条目的状态如果为M、E或者S,那么该处理器可以直接从相应的缓存行中读取地址A所对应的数据，而无须往总线中发送任何消息
>>2. 如果P1找到的缓存条目的状态为I，则说明该处理器的高速缓存中并不包含S的有效副本数据，此时P1需要往总线发送Read消息以读取地址A对应的数据，而其他处理器P2（或者主内存）则需要回复ReadResponse以提供相应的数据
>>3. P1接收到ReadResponse消息时，会将其中携带的数据（包含数据S的数据块）存入相应的缓存行并将相应缓存条目的状态更新为S。P1接收到的ReadResponse消息可能来自主内存也可能来自其他处理器（P2）。
>>4. P2会嗅探总线中由其他处理器发送的消息。P2嗅探到Read消息的时候，会从该消息中取出待读取的内存地址，并根据该地址在其高速缓存中查找对应的缓存条目。如果P2找到的缓存条目的状态不为I,则说明该处理器的高速缓存中有待读取数据的副本，此时P2会构造相应的ReadResponse消息并将相应缓存行所存储的整块数据（而不仅仅是P1所请求的数据S）“塞入”该消息。如果P2找到的相应缓存条目的状态为M，那么P2可能在往总线发送ReadResponse消息前将相应缓存行中的数据写入主内存。P2往总线发送ReadResponse之后，相应缓存条目的状态会被更新为S。
>>5. 如果P2找到的高速缓存条目的状态为I，那么P1所接收到的ReadResponse消息就来自主内存。
可见，在P1读取内存的时候，即便P2对相应的内存数据进行了更新且这种更新还停留在P2的高速缓存中而造成高速缓存与主内存中的数据不一致，在MESI消息的协调下这种不一致也并不会导致P1读取到一个过时的旧值。

>2. 例子2： 处理器写值(任何一个处理器执行内存写操作时必须拥有相应数据的所有权)
假设: 假设现在有有处理器P1向内存地址A，写入数据S
>>1. 在执行内存写操作时，P1会先根据内存地址A找到相应的缓存条目。P1所找到的缓存条目的状态若为E或者M，则说明该处理器已经拥有相应数据的所有权，此时该处理器可以直接将数据写入相应的缓存行并将相应缓存条目的状态更新为M。
>>2. 所找到的缓存条目的状态如果不为E、M，则该处理器需要往总线发送Invalidate消息以获得数据的所有权。其他处理器接收到Invalidate消息后会将其高速缓存中相应的缓存条目状态更新为I（相当于删除相应的副本数据）并回复Invalidate Acknowledge消息。 发送Invalidate消息的处理器（即内存写操作的执行处理器），必须在接收到其他所有处理器所回复的所有InvalidateAcknowledge消息之后再将数据更新到相应的缓存行之中，
>>3. P1所找到的缓存条目的状态若为S，则说明P2上的高速缓存可能也保留了地址A对应的数据副本，此时P1需要往总线发送Invalidate消息。P1在接收到其他所有处理器所回复的Invalidate Acknowledge消息之后会将相应的缓存条目的状态更新为E，此时P1获得了地址A上数据的所有权。接着，P1便可以将数据写入相应的缓存行，并将相应的缓存条目的状态更新为M。
>>4. P1所找到的缓存条目的状态若为I，则表示该处理器不包含地址A对应的有效副本数据，此时P1需要往总线发送Read Invalidate消息。P1在接收到Read Response消息以及其他所有处理器所回复的Invalidate Acknowledge消息之后，会将相应缓存条目的状态更新为E，这表示该处理器已经获得相应数据的所有权。接着，P1便可以往相应的缓存行中写入数据了并将相应缓存条目的状态更新为M。 其他处理器在接收到Invalidate消息或者Read Invalidate消息之后，必须根据消息中包含的内存地址在该处理器的高速缓存中查找相应的高速缓存条目。若P2所找到的高速缓存条目的状态不为I,那么P2必须将相应缓存条目的状态更新为I，以删除相应的副本数据并给总线回复Invalidate Acknowledge消息。

#### 3. 写缓冲器和无效化队列
MESI协议解决了缓存一致性问题，但是其自身也存在一个性能弱点——处理器执行写内存操作时，必须等待其他所有处理器将其高速缓存中的相应副本数据删除并接收到这些处理器所回复的Invalidate Acknowledge/Read Response消息之后才能将数据写入高速缓存。为了规避和减少这种等待造成的写操作的延迟（Latency），硬件设计者引入了写缓冲器和无效化队列。
![Alt "处理器项目图"](https://github.com/LCN29/Picture-Repository/blob/master/MyNote/Book/processor.png?raw=true)

(1)写缓冲器（StoreBuffer，也被称为WriteBuffer）是处理器内部的一个容量比高速缓存还小的私有高速存储部件,每个处理器都有其写缓冲器，写缓冲器内部可包含若干条目。一个处理器无法读取另外一个处理器上的写缓冲器中的内容。

(2)引入写缓冲器之后，处理器在执行写操作时会做这样的处理：
>1. 如果相应的缓存条目状态为E或者M，那么处理器可能会直接将数据写入相应的缓存行而无须发送任何消息
>2. 如果相应的缓存条目状态为S，那么处理器会先将写操作的相关数据（包括数据和待操作的内存地址）存入写缓冲器的条目之中，并发送Invalidate消息
>3. 如果相应的缓存条目状态为I，我们就称相应的写操作遇到了写未命中（WriteMiss），那么此时处理器会先将写操作相关数据存入写缓冲器的条目之中，并发送Read Invalidate消息。 (我们知道在其他所有处理器的高速缓存都未保存指定地址的副本数据的情况下，Read消息回复者是主内存，也就是说Read消息可能导致内存读操作。因此，写未命中的开销是比较大的。)
>4. 内存写操作的执行处理器在将写操作的相关数据写入写缓冲器之后便认为该写操作已经完成，即该处理器并不等待其他处理器返回Invalidate Acknowledge/Read Response消息而是继续执行其他指令（比如执行读操作）。一个处理器接收到其他处理器所回复的针对同一个缓存条目的所有Invalidate Acknowledge消息的时候，该处理器会将写缓冲器中针对相应地址的写操作的结果写入相应的缓存行中，此时写操作对于其执行处理器之外的其他处理器来说才算是完成的。

(3)由此可见，写缓冲器的引入使得处理器在执行写操作的时候可以不等待Invalidate Acknowledge消息，从而减少了写操作的延时，这使得写操作的执行处理器在其他处理器回复Invalidate Acknowledge/Read Response消息这段时间内能够执行其他指令，从而提高了处理器的指令执行效率。

(4)引入无效化队列（Invalidate Queue）之后，处理器在接收到Invalidate消息之后并不删除消息中指定地址对应的副本数据，而是将消息存入无效化队列之后就回复InvalidateAcknowledge消息，从而减少了写操作执行处理器所需的等待时间。

(5)引入写缓冲器之后，处理器在执行读操作的时候不能根据相应的内存地址直接读取相应缓存行中的数据作为该操作的结果。 这是因为一个处理器在更新一个变量之后，紧接着又读取该变量的值的时候，由于该处理器先前对该变量的更新结果可能仍然还停留在写缓冲器之中，因此该变量相应的内存地址所对应的缓存行中存储的值是该变量的旧值。这种情况下为了避免读操作所返回的结果是一个旧值，处理器在执行读操作的时候会根据相应的内存地址查询写缓冲器。如果写缓冲器存在相应的条目，那么该条目所代表的写操作的结果数据就会直接作为该读操作的结果返回；否则，处理器才从高速缓存中读取数据。这种处理器直接从写缓冲器中读取数据来实现内存读操作的技术被称为存储转发（StoreForwarding）。存储转发使得写操作的执行处理器能够在不影响该处理器执行读操作的情况下将写操作的结果存入写缓冲器。

(6)写缓冲器和无效化队列的引入又会带来一些新的问题 —— 内存重排序。
>1. 写缓冲器可能导致StoreLoad重排序（Stores Reordered After Loads）

|Processor1                | Processor2 |
| :-                       | :-  |
| X = 1;  // Sl            |  Y = 1; // S3|
| r1 = Y; // L2            |              |
|                          | r2 = X; //L4|

如图：X, Y为共享变量(初始0), r1,r2为局部变量(初始0)。
当Processor1上的线程执行到L2时，虽然在此之前S3已经被Processor2执行完毕，但是由于S3的执行结果可能仍然还停留在Processor2的写缓冲器中，而一个处理器无法读取另外一个处理器的写缓冲器中的内容，因此Processor1此刻读取到的Y的值仍然是其高速缓存中存储的该变量的初始值0。同理，Processor1执行到L4时所读取到变量X的值也可能是该变量的初始值0。因此，从Processor2的角度来看，Processor2执行L4的那一刻Processor1已经执行了L2而S1却像是尚未被执行，即Processor2对Processor01执行的两个操作的感知顺序是L2→S1,也就是说此时写缓冲器导致了S1（写操作）被重排序到了L2（读操作）之后。

>2. 写缓冲器可能导致StoreStore重排序（Stores Reordered After Stores）。

|Processor1                | Processor2 |
| :-                       | :-         |
| data = 1; //S1           |            |
| ready = true; //S2       |            |
|                          | while(!ready) continue; //L3|
|                          | println(data)           //L4|

如图：data,ready为共享变量(初始为0,false), Processor1包含变量ready的副本但不包含变量data的副本
假设Processor1执行S1, S2时, S1的执行结果会先被存入写缓冲器, 而S2的执行结果会直接被存入高速缓存。 L3被执行时S2对ready的更新, 通过缓存一致性协议可以被Processor2读取到。 由于ready值已变为true, 因此Processor2继续执行L4。 L4被执行的时候, 由于S1对data的更新结果可能仍然停留在Processor1的写缓冲器之中, 因此Processor2此时读取到的变量data的值可能仍然是其初始值0, 即L4的输出结果可能仍然是0而不是Processor2所期望的新值(Processor1更新之后的值)。 从Processor2的角度来看, 这就造成了一种现象——S2像是先于S1被执行, 即S1(写操作)被重排序(内存重排序)到了S2(写操作)之后。

>3. 无效化队列可能导致LoadLoad重排序（LoadsReorderedAfterLoads）。

|Processor1                | Processor2 |
| :-                       | :-         |
| data = 1; //S1           |            |
| ready = true; //S2       |            |
|                          | while(!ready) continue; //L3|
|                          | println(data)           //L4|

如图： data, ready为共享变量(初始为0, false)， Processor1包含变量ready, data的副本, Processor2包含变量data的副本但不包含变量ready的副本
>>1. Processor1执行S1。 此时由于Processor2上也存有变量data的副本, 因此Processor1会发出Invalidate消息并将S1的操作结果存入写缓冲器。 
>>2. Processor2接收到Processor1发出的Invalidate消息时将该消息存入其无效化队列并回复Invalidate Acknowledge消息。
>>3. Processor1接收到Invalidate Acknowledge消息, 随即将S1的操作结果写入高速缓存。 然后, Processor1执行S2。 此时由于只有Processor1上存有变量ready的副本, 因此Processor1无须发送任何消息, 直接将S2的操作结果存入高速缓存即可。 
>>4. Processor2执行L3。 此时由于Processor2的高速缓存中并没有存储变量ready的副本, 因此Processor2会发出一个Read消息。  
>>5. Processor1接收到Processor2发出的Read消息并回复Read Response消息。 由于此时Processor1已经执行过S2, 因此该Read Response消息包含的ready变量值为true。 
>>6. Processor2接收到Read Response消息并从中取出ready变量的新值(true), 此时L3中的循环语句可以结束。 
>>7. Processor2执行L4。 此时, 由于Processor1为了更新变量data而发出的Invalidate消息可能仍然还停留在Processor2的无效化队列中, 因此Processor1从其高速缓存中读取的变量data的值仍然是其初始值。 因此, L4所打印的变量值可能是一个旧值。 

(6)写缓冲器和无效化队列的引入又会带来一些新的问题 —— 可见性。
一个处理器中的写缓冲器所存储的内容是无法被其他处理器所读取的。 因此, 一个处理器上运行的线程更新了一个共享变量之后, 其他处理器上运行的线程再来读取该变量时这些线程可能仍然无法读取到前一个线程对该变量所做的更新, 因为这个更新可能还停留在前一个线程所在的处理器上的写缓冲器之中, 这就是可见性问题。 因此, 我们说写缓冲器是可见性问题的硬件根源。
为了使一个处理器上运行的线程对共享变量所做的更新可以被其他处理器上运行的其他线程所读取, 我们必须将写缓冲器中的内容写入其所在的处理器上的高速缓存之中, 从而使该更新在缓存一致性协议的作用下可以被其他处理器读取到。 

>1. 处理器在一些特定条件下(比如写缓冲器满、I/O指令被执行)会将写缓冲器排空(Drain)或者冲刷(Flush), 即将写缓冲器中的内容写入高速缓存, 但是从程序对一个或者一组变量更新的角度来看, 处理器本身并无法保证这种冲刷对程序来说是"及时"的。 因此, 为了保证一个处理器对共享变量所做的更新可以被其他处理器同步, 编译器等底层系统需要借助一类被称为内存屏障的特殊指令。 内存屏障中的存储屏障(Store Barrier)可以使执行该指令的处理器冲刷其写缓冲器。 

>2. 然而, 冲刷写缓冲器只是解决了可见性问题的一半。 因为可见性问题的另一半是无效化队列导致的 —— 处理器在执行内存读取操作前如果没有根据无效化队列中的内容将该处理器上的高速缓存中的相关副本数据删除, 那么就可能导致该处理器读到的数据是过时的旧数据, 从而使得其他处理器所做的更新丢失。 因此, 为了使一个处理器上运行的线程能够读取到另外一个处理器上运行的线程对共享变量所做的更新, 该处理器必须先根据无效化队列中存储的Invalidate消息删除其高速缓存中的相应副本数据, 从而使其他处理器上运行的线程对共享变量所做的更新在缓存一致性协议的作用下能够被同步到该处理器的高速缓存之中。 内存屏障中的加载屏障(Load Barrier)正是用来解决这个问题的。 加载屏障会根据无效化队列内容所指定的内存地址, 将相应处理器上的高速缓存中相应的缓存条目的状态都标记为I, 从而使该处理器后续执行针对相应地址(无效化队列内容中指定的地址)的读内存操作时必须发送Read消息, 以将其他处理器对相关共享变量所做的更新同步到该处理器的高速缓存中。 

>3. 存储转发技术也可能导致可见性问题。 假设处理器P1在t1时刻更新了某个共享变量, 随后又在t2时刻读取了该变量。 在t1时刻到t2时刻之间的这段时间内其他处理器可能已经更新了该共享变量, 并且这个更新的结果已经到达该处理器的高速缓存。 但是如果P1在t1时刻所做的更新仍然停留在该处理器的写缓冲器之中, 那么存储转发技术会使P1直接从其写缓冲器读取该共享变量的值。 也就是说P1此时根本不从高速缓存中读取该变量的值, 这就使得另外一个处理器对该共享变量所做的更新无法被该处理器读取, 从而导致P1在t2时刻读取到的变量值是一个旧值。 

>4. 解决可见性问题首先要使写线程对共享变量所做的更新能够到达(被存储到)高速缓存, 从而使该更新对其他处理器是可同步的。 其次, 读线程所在的处理器要将其无效化队列中的内容“应用”到其高速缓存上, 这样才能够将其他处理器对共享变量所做的更新同步到该处理器的高速缓存中。 而这两点是通过存储屏障与加载屏障的成对使用实现的：写线程的执行处理器所执行的存储屏障保障了该线程对共享变量变量所做的更新对读线程来说是可同步的；读线程的执行处理器所执行的加载屏障将写线程对共享变量所做的更新同步到该处理器的高速缓存之中。 

(6) 基本内存屏障
处理器支持哪种内存重排序(LoadLoad重排序、LoadStore重排序、StoreStore重排序和StoreLoad重排序), 就会提供能够禁止相应重排序的指令, 这些指令就被称为基本内存屏障——LoadLoad屏障、LoadStore屏障、StoreStore屏障和StoreLoad屏障。 基本内存屏障可以统一用XY来表示, 其中的X和Y可以代表Load或者Store。 基本内存屏障是对一类指令的称呼, 这类指令的作用是禁止该指令左侧的任何X操作与该指令右侧的任何Y操作之间进行重排序, 从而确保该指令左侧的所有X操作先于该指令右侧的Y操作被提交, 即内存操作作用到主内存(或者高速缓存)上。

>1. 基本内存屏障的具体作用
| 屏障名称 | 具体作用|
|:-| -:|
| StoreLoad |禁止StoreLoad重排序, 即确保该屏障之前的任何一个写操作的结果都会在该屏障之后的任何一个读操作的数据被加载之前对其他处理器来说是可同步的(被写入高速缓存(或者主内存))|
| StoreStore|禁止StoreStore重排序, 即确保该屏障之前的任何一个写操作的结果都会在该屏障之后的任何一个写操作之前对其他处理器来说是可同步的|
| LoadLoad  |禁止LoadLoad重排序, 即确保该屏障之前的任何一个读操作的数据都会在该屏障之后的任何一个读操作之前被加载|
| LoadStore |禁止LoadStore重排序, 即确保该屏障之前的任何一个读操作的数据都会在该屏障之后的任何一个写操作的结果被冲刷(写入)到高速缓存(或者主内存)之前被加载|

>2. 基本内存屏障的作用只是保障其左侧的X操作(比如读, 即X代表Load)先于其右侧的Y操作(比如写, 即Y代表Store)被提交, 它并不全面禁止重排序。 XY屏障两侧的内存操作仍然可以在不越过内存屏障本身的情况下在各自的范围内进行重排序, 并且XY屏障左侧的非X操作与屏障右侧的非Y操作之间仍然可以进行重排序(即越过内存屏障本身)。 例如, 在图11-7所示的指令序列中Load2、Load3和Store1、Store2之间无法进行重排序, 而Store1、Load1和Store2之间可以重排序, Store3、Load2和Load3之间可以重排序, Load1和Store3之间也可以进行重排序。
![Alt '内存屏障'](https://github.com/LCN29/Picture-Repository/blob/master/MyNote/Book/barrier.png?raw=true) 

>3. LoadLoad屏障是通过清空无效化队列来实现禁止LoadLoad重排序的。 LoadLoad屏障会使其执行处理器根据无效化队列中的Invalidate消息删除其高速缓存中相应的副本。 这个过程被称为将无效化队列应用到高速缓存, 也被称为清空无效化队列, 它使处理器有机会将其他处理器对共享变量所做的更新同步到该处理器的高速缓存中, 从而消除了LoadLoad重排序的根源而实现了禁止LoadLoad重排序

>4. StoreStore屏障可以通过对写缓冲器中的条目进行标记来实现禁止StoreStore重排序。 StoreStore屏障会将写缓冲器中的现有条目做一个标记, 以表示这些条目代表的写操作需要先于该屏障之后的写操作被提交。 处理器在执行写操作的时候如果发现写缓冲器中存在被标记的条目, 那么即使这个写操作对应的高速缓存条目的状态为E或者M, 此时处理器也不直接将写操作的数据写入高速缓存, 而是将其写入写缓冲器, 从而使得StoreStore屏障之前的任何写操作先于该屏障之后的写操作被提交。 

>5. 就处理器的具体实现而言, 许多处理器往往将StoreLoad屏障实现为一个通用基本内存屏障(General-purposeBarrier), 即StoreLoad屏障能够实现其他3种基本内存屏障的效果。 StoreLoad屏障能够替代其他基本内存屏障, 但是它的开销也是最大的——StoreLoad屏障会清空无效化队列, 并将写缓冲器中的条目冲刷(写入)高速缓存。 因此, StoreLoad屏障既可以将其他处理器对共享变量所做的更新同步到该处理器的高速缓存中, 又可以使其执行处理器对共享变量所做的共享对其他处理器来说可同步。 


#### 4.Java同步机制和内存屏障

(1) volatile关键字的实现
```java
   
   int A;

   int B;

   volatile boolean V;

   public class writeThread {

       public void write() {

          A = 1;
          B = 1;
          [LoadStore + StoreStore] // 释放屏障
          V = true;
          [StoreLoad]
       }
   }
   

   public class readThread {

       public void read() {
        
         [LoadLoad]
         if (V) {
             [LoadLoad, LoadStore]   //获取屏障
             int sum = A + B;
         }
       }
   }
```
A、B是普通共享变量, V是volatile变量。 
>1. 释放屏障确保了写线程对共享变量A、B的更新会先于对V的更新被提交, 这就意味着读线程在读取到写线程对V的更新情况下也能够读取到写线程对A和B的更新。 
>2. 为了保障读线程对写线程所执行的写操作的感知顺序与程序顺序一致, 读线程必须依照与写线程的程序顺序的相反顺序即先读取V再读取A或者B来执行读操作。 
>3. 为了保障读线程对写线程所执行的写操作的感知顺序与程序顺序一致, 读线程必须依照与写线程的程序顺序的相反顺序即先读取V再读取A或者B来执行读操作。 
>4. 由于读线程中的读操作(或写操作)也可能会被重排序(包括指令重排序和内存重排序), 因此Java虚拟机会在读线程中的volatile读操作之后插入一个获取屏障, 以保证该线程对变量V的读取操作先于对A、B的读取操作被提交。 
>5. 写线程、读线程通过释放屏障和获取屏障的这种配对使用保障了读线程对写线程执行的写操作的感知顺序与程序顺序一致, 即保障了有序性。 

释放屏障只是确保了该屏障之前的读、写操作先于该屏障之后的任何写操作被提交, 因此释放屏障之前的操作之间, 其提交顺序可以与程序顺序不一致。 获取屏障只是确保了该屏障之前的任何读操作先于该屏障之后的任何读、写操作被提交。 因此获取屏障之后的操作之间, 其提交顺序可以与程序顺序不一致。 

Java虚拟机(JIT编译器)会在volatile变量写操作之后插入一个StoreLoad屏障。 其作用有
>1. 禁止该屏障之后的任何读操作与该屏障之前的任何写操作(包括该volatile写操作)之间进行重排序
>2. 充当存储屏障。 StoreLoad屏障是一个通用存储屏障, 其功能涵盖了其他3个基本内存屏障。 StoreLoad屏障通过清空其执行处理器的写缓冲器使得该屏障前的所有写操作(包括volatile写操作以及其他任何写操作)的结果得以到达高速缓存, 从而使这些更新对其他处理器而言是可同步的。 
>3. 这是利用了StoreLoad屏障既能够清空写缓冲器还能够清空无效化队列的功能, 从而使其他处理器对volatile变量所做的更新能够被同步到volatile变量读线程的执行处理器上。 (解决：存储转发技术可能使得一个处理器无法将其他处理器对共享变量所做的更新同步到该处理器的高速缓存上)

Java虚拟机(JIT编译器)在volatile变量读操作前插入的一个加载屏障相当于LoadLoad屏障。其作用有
>1. 通过清空无效化队列来使得其后的读操作(包括volatile读操作)有机会读取到其他处理器对共享变量所做的更新。 